{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meg-huggingface/bias-testing/blob/main/fineweb_bias_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load packages"
      ],
      "metadata": {
        "id": "utSDkGUL101i"
      },
      "id": "utSDkGUL101i"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "34299990-bd58-4fe9-99fe-15d4b6796106",
      "metadata": {
        "id": "34299990-bd58-4fe9-99fe-15d4b6796106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6bfe03-0a0f-42b0-cd36-61a3ee9232c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: datatrove in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: dill>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datatrove) (0.3.8)\n",
            "Requirement already satisfied: fsspec>=2023.12.2 in /usr/local/lib/python3.10/dist-packages (from datatrove) (2024.3.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from datatrove) (0.23.1)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from datatrove) (4.7.0)\n",
            "Requirement already satisfied: loguru>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from datatrove) (0.7.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datatrove) (0.70.16)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from datatrove) (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from datatrove) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->datatrove) (3.14.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->datatrove) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->datatrove) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->datatrove) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->datatrove) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->datatrove) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->datatrove) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->datatrove) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->datatrove) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install datatrove\n",
        "import datasets\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from datatrove.pipeline.readers import ParquetReader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "703c7781-0a33-41dc-8da9-2fa034483cad",
      "metadata": {
        "id": "703c7781-0a33-41dc-8da9-2fa034483cad"
      },
      "source": [
        "## Methodology\n",
        "\n",
        "In order to measure bias in the dataset, we consider the following simple [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) based approach. The idea is that the specificity of a term -- in our case, how `biased` it is -- can be quantified as an inverse function of the number of documents in which it occurs.\n",
        "\n",
        "Given a dataset and terms for a subpopulation (gender) of interest:\n",
        "1. Evaluate Inverse Document Frequencies on the full dataset\n",
        "2. Compute the average TF-IDF vectors for the dataset for a given subpopulation (gender)\n",
        "3. Sort the terms by variance to see words that are much more likely to appear specifically for a given subpopulation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c837c65-987f-45cf-b18d-fc7836894372",
      "metadata": {
        "id": "7c837c65-987f-45cf-b18d-fc7836894372"
      },
      "source": [
        "### Load Fineweb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "dbd19018",
      "metadata": {
        "id": "dbd19018"
      },
      "outputs": [],
      "source": [
        "data_reader = ParquetReader(\"hf://datasets/HuggingFaceFW/fineweb/data/CC-MAIN-2024-10\", progress=True)#, limit=10000)\n",
        "corpus = map(lambda doc: doc.text, data_reader())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute frequencies"
      ],
      "metadata": {
        "id": "eBj1TtiW2C-6"
      },
      "id": "eBj1TtiW2C-6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a CountVectorizer object\n",
        "#count_vect = CountVectorizer(stop_words='english')\n",
        "# Fit and transform the data\n",
        "#counts = count_vect.fit_transform(corpus)\n",
        "# Create a TfidfTransformer object\n",
        "#tfidf_transformer = TfidfTransformer()\n",
        "# Fit and transform the data\n",
        "#tfidf = tfidf_transformer.fit_transform(counts)\n",
        "\n",
        "\n",
        "# Step 1: get Inverse document frequencies for the dataset\n",
        "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "full_tfidf = vectorizer.fit_transform(corpus)\n",
        "tfidf_feature_names = np.array(vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOi2tMVr7ORS",
        "outputId": "877b9ad6-2b4e-421d-c9eb-d67204468d5a"
      },
      "id": "fOi2tMVr7ORS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\u001b[32m2024-05-31 00:42:48.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mReading input file 000_00000.parquet\u001b[0m\n",
            "1000983it [20:49, 1889.51it/s]\u001b[32m2024-05-31 01:03:37.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mReading input file 000_00001.parquet\u001b[0m\n",
            "1998983it [43:10, 1417.98it/s]\u001b[32m2024-05-31 01:25:58.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdatatrove.pipeline.readers.base\u001b[0m:\u001b[36mread_files_shard\u001b[0m:\u001b[36m193\u001b[0m - \u001b[1mReading input file 000_00002.parquet\u001b[0m\n",
            "2428949it [52:56, 1163.31it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bias analysis: Gender tf-idf"
      ],
      "metadata": {
        "id": "aqIybwilj0KH"
      },
      "id": "aqIybwilj0KH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: get average TF-IDF vectors **for each gender**\n",
        "woman_docs = map(lambda doc: doc.text, filter(lambda doc: \"woman\" in doc.text.split(), data_reader()))\n",
        "man_docs = map(lambda doc: doc.text, filter(lambda doc: \"man\" in doc.text.split(), data_reader()))\n",
        "tfidf_by_gender = {}\n",
        "tfidf_by_gender[\"man\"] = np.asarray(vectorizer.transform(man_docs).mean(axis=0))[0]\n",
        "tfidf_by_gender[\"woman\"] = np.asarray(vectorizer.transform(woman_docs).mean(axis=0))[0]"
      ],
      "metadata": {
        "id": "d-Na79jvczt0"
      },
      "id": "d-Na79jvczt0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_by_gender)"
      ],
      "metadata": {
        "id": "M4SiqpLkECAj"
      },
      "id": "M4SiqpLkECAj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: for each term, compute the variance across genders\n",
        "all_tfidf = np.array(list(tfidf_by_gender.values()))\n",
        "tf_idf_var = all_tfidf - all_tfidf.sum(axis=0, keepdims=True)\n",
        "tf_idf_var = np.power((tf_idf_var * tf_idf_var).sum(axis=0), 0.5)\n",
        "sort_by_variance = tf_idf_var.argsort()[::-1]"
      ],
      "metadata": {
        "id": "D0sbbLyWw2CZ"
      },
      "id": "D0sbbLyWw2CZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_tfidf)"
      ],
      "metadata": {
        "id": "AMOmeMhT8r63"
      },
      "id": "AMOmeMhT8r63",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03393fe5-2a92-451a-bd08-6a27a6239097",
      "metadata": {
        "id": "03393fe5-2a92-451a-bd08-6a27a6239097"
      },
      "outputs": [],
      "source": [
        "# Create the data structure for the visualization,\n",
        "# showing the highest variance words for each gender,\n",
        "# and how they deviate from the mean\n",
        "pre_pandas_lines = [\n",
        "    {\n",
        "        \"word\": tfidf_feature_names[w],\n",
        "        \"man\": all_tfidf[0, w],\n",
        "        \"woman\": all_tfidf[1, w],\n",
        "        \"man+\": all_tfidf[0, w] - all_tfidf[:, w].mean(),\n",
        "        \"woman+\": all_tfidf[1, w] - all_tfidf[:, w].mean(),\n",
        "        \"variance\": tf_idf_var[w],\n",
        "        \"total\": all_tfidf[:, w].sum(),\n",
        "    }\n",
        "    for w in sort_by_variance[:50]\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "IhJC-iT91smy"
      },
      "id": "IhJC-iT91smy"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "df = pd.DataFrame.from_dict(pre_pandas_lines)\n",
        "df.style.background_gradient(\n",
        "    axis=None,\n",
        "    vmin=0,\n",
        "    vmax=0.2,\n",
        "    cmap=\"YlGnBu\"\n",
        ").format(precision=2)"
      ],
      "metadata": {
        "id": "LDLjFa6HdMWe"
      },
      "id": "LDLjFa6HdMWe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e273abff-3d81-431f-9188-82d87d1ecda2",
      "metadata": {
        "id": "e273abff-3d81-431f-9188-82d87d1ecda2"
      },
      "source": [
        "#### Sorting by bias\n",
        "\n",
        "In order to better surface biases, we can sort the table by how much one gender over-represents a term.\n",
        "\n",
        "In this case, we see that instances mentioning `man` are more likely to include `god` than those mentioning `woman`, which in turn are more likely to include `cancer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34229f06-5bf7-4ece-b43e-7d453931abd4",
      "metadata": {
        "id": "34229f06-5bf7-4ece-b43e-7d453931abd4",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.sort_values('man+', ascending=False).style.background_gradient(\n",
        "    axis=None,\n",
        "    vmin=0,\n",
        "    vmax=0.2,\n",
        "    cmap=\"YlGnBu\"\n",
        ").format(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values('woman+', ascending=False).style.background_gradient(\n",
        "    axis=None,\n",
        "    vmin=0,\n",
        "    vmax=0.2,\n",
        "    cmap=\"YlGnBu\"\n",
        ").format(precision=2)"
      ],
      "metadata": {
        "id": "ufATwOCojOdv"
      },
      "id": "ufATwOCojOdv",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}